---
title: 'Programming Interview Fundamentals'
date: '2020-02-07 05:47:49'
tags: []
draft: false
summary: ''
images: []
---

<p>Notes for reviewing <strong>computer science and programming interview  fundamentals</strong>. Helpful for last minute pre-interview studying!</p>



<h2>Problem Approach</h2>



<p><strong>ESTCV (Examples, Solutions/Approach, Test Cases, Code, Verify)</strong></p>



<h2>Time Complexity</h2>



<ul><li>If a problem is halved each time, likely O(log(n)).</li><li>If algorithm is in the form of "Do this then when done do that", then you add the runtimes. (Two separate loops).</li><li>If algorithm is in the form of "Do this for each time you do that" then you multiple the runtimes. (Loops within Loops).</li></ul>



<table class="wp-block-table"><tbody><tr><td>Sorting Algorithm</td><td>Time</td></tr><tr><td>Selection Sort</td><td>n^2</td></tr><tr><td>Insertion Sort</td><td>n - n^2</td></tr><tr><td>Quick Sort</td><td>nLog(n) - n^2</td></tr><tr><td>Merge Sort</td><td>nLog(n)</td></tr><tr><td>Heap Sort</td><td>nLog(n)</td></tr></tbody></table>



<table class="wp-block-table"><tbody><tr><td>Data Structures</td><td>Average</td><td>Worst</td></tr><tr><td>Array</td><td>O(n)</td><td>O(n)</td></tr><tr><td>Stack</td><td>O(n)</td><td>O(1)</td></tr><tr><td>Queue</td><td>O(n)</td><td>O(1)</td></tr><tr><td>Hash</td><td>O(1)</td><td>O(n)</td></tr><tr><td>Binary Search Tree</td><td>O(log(n))</td><td>O(log(n))</td></tr></tbody></table>



<h2>Trees</h2>



<h3>Binary Search Tree</h3>



<p>A binary search search tree imposes the condition that for all nodes, the left children are less than or equal to the current node which is less than all the right nodes. </p>



<h3>Balanced Trees</h3>



<p>Balancing a tree implies only that the depth of subtrees will not vary by more than a certain amount. It does not mean that the right &amp; left subtree are exactly the same.</p>



<h3>Full &amp; Complete Trees</h3>



<p>Full and Complete trees have all leaves at the bottom &amp; all non-leaf nodes have exactly two children. Must have 2^n -1 nodes to meet the condition.</p>



<h3>Tree Balancing &amp; Graph Transversal</h3>



<p>Depth first search (DFS) is easier if you want to visit each node. If the tree is really big, you want to use Breath First Search (BFS) to quit when you get too far from the original node.</p>



<h4>Depth First Search</h4>



<p>In Depth First Search, we visit a node <strong>r</strong> and then iterate through each of <strong>r</strong>'s adjacent node. When visiting a node <strong>n</strong> that is adjacent to <strong>r</strong>, we visit all of <strong>n</strong>'s adjacent node before going on to <strong>r</strong>'s other adjacent nodes. That is, <strong>n</strong>, is exhaustively searched before <strong>r</strong> moves on to searching its other children.</p>



<p><strong>Searching a node and all it's children before proceeding to siblings.</strong></p>



<h4>Breadth First Search</h4>



<p>Breadth First Search is considerably less intuitive. We visit each of a node <strong>r</strong>'s adjacent nodes before searching any of <strong>r'</strong>s grandchildren. An iterative solution involing a queue usually works best.</p>



<p><strong>Searching a node and it's silblings before any children. Use queue.</strong></p>



<h3>Tries *try*</h3>



<p>A tree with each node having N possible nodes to build a path for finding a word. The word is broken up, a character per node. The next word is broken up and inserted to any existing paths. </p>



<h3>Must Know Tree Algorithm</h3>



<ul><li>In Order<ul><li>Go left node, current, then right (BST)</li></ul></li><li>Pre Order<ul><li>Go current, then left, then right</li></ul></li><li>Post Order<ul><li>Go left, right, then current</li></ul></li><li>Insert Node<ul><li>BST, insert by comparing to root if <strong>Insert</strong> &gt; root, go right, else go left. Go until an empty spot.</li></ul></li></ul>



<h2>Recursion</h2>



<p>A good hint is to be built off sub-problems. Some things to watch for</p>



<ul><li>Can the problem be solved iteratively &amp; better?</li><li>Recursive algorithms cost a lot of space. Each recursive call adds a new layer to the stach. O(n) call = O(n) memory.</li><li>Dynamic programming is mostly taking a recursive algorithm, finding overlapping subproblems and caching results.</li></ul>



<p>Appoaching problem by..</p>



<ol><li>How many sub problems does f(n) depend on?</li><li>Solve for a base case</li><li>Solve for f(2)</li><li>solve for f(3), understand the exact process of translating to subs.</li><li>solve f(n)</li></ol>



<h2>Searching Algorithms</h2>



<ul><li>Bubble Sort | O(n^2)<ul><li>Start at beginning of array, swap first two elements, go to next pair until sorted. </li></ul></li><li>Selection Sort | O(n^2)<ul><li>Find the smallest element in array, move to front of array, then find the second smallest and move it to second place. Repeat.</li></ul></li><li>Merge Sort | O(nLog(n))<ul><li>Sort each pair of elements, then sort every four elements by merging the pairs, then sort every 8 elements. </li></ul></li><li>Quick Sort | Expecting: O(nLog(n)) Worst: O(n^2)<ul><li>Pick a random element and partition the array such that all numbers are less than it come before all elements that are greater than it. Then do that for each half.</li></ul></li><li>Bucket Sort | O(m+n)<ul><li>Partition the array into finite number of buckets then sort each bucket individually. N = number of items. M = number of distinct items.</li></ul></li></ul>